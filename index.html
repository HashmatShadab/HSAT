<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta content="DESCRIPTION META TAG" name="description">
    <meta content="SOCIAL MEDIA TITLE TAG" property="og:title"/>
    <meta content="SOCIAL MEDIA DESCRIPTION TAG TAG" property="og:description"/>
    <meta content="URL OF THE WEBSITE" property="og:url"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta content="static/image/your_banner_image.png" property="og:image"/>
    <meta content="1200" property="og:image:width"/>
    <meta content="630" property="og:image:height"/>


    <meta content="TWITTER BANNER TITLE META TAG" name="twitter:title">
    <meta content="TWITTER BANNER DESCRIPTION META TAG" name="twitter:description">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta content="static/images/your_twitter_banner_image.png" name="twitter:image">
    <meta content="summary_large_image" name="twitter:card">
    <!-- Keywords for your paper to be indexed by-->
    <meta content="KEYWORDS SHOULD BE PLACED HERE" name="keywords">
    <meta content="width=device-width, initial-scale=1" name="viewport">


    <title>HSAT:Hierarchical Self-Supervised Adversarial Training for Robust Vision Models in Histopathology</title>
    <link href="static/images/favicon.ico" rel="icon" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link href="static/css/bulma.min.css" rel="stylesheet">
    <link href="static/css/bulma-carousel.min.css" rel="stylesheet">
    <link href="static/css/bulma-slider.min.css" rel="stylesheet">
    <link href="static/css/fontawesome.all.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
          rel="stylesheet">
    <link href="static/css/index.css" rel="stylesheet">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">HSAT:Hierarchical Self-Supervised Adversarial Training for
                        Robust Vision Models in Histopathology</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                <a href="https://scholar.google.com/citations?user=2Ft7r4AAAAAJ&hl=en" target="_blank">Hashmat Shadab Malik</a><sup>1</sup>,</span>
                        <span class="author-block">
                  <a href="https://github.com/ShahinaKK"
                     target="_blank">Shahina Kunhimon</a><sup>1</sup>,</span>
                        <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=tM9xKA8AAAAJ&hl=en" target="_blank">Muzammal Naseer</a><sup>2</sup>,</span>
                        </span>
                        <span class="author-block">
                        <a href="https://scholar.google.com/citations?user=zvaeYnUAAAAJ&hl=en" target="_blank">Fahad Shahbaz Khan</a><sup>1,3</sup>,</span>
                        </span>
                        <span class="author-block">
                            <a href="https://scholar.google.com/citations?user=M59O9lkAAAAJ&hl=en" target="_blank">Salman Khan</a><sup>1,4</sup>
                    </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Mohamed bin Zayed University of Artificial Intelligence, UAE<br>
                    <span class="author-block"><sup>2</sup>Center of Secure Cyber-Physical Security Systems, Khalifa University, UAE<br>
                    <span class="author-block"><sup>3</sup>Linköping University <br>
                      <span class="author-block"><sup>4</sup>Australian National University <br>(Under Review)</span>


                        <!--                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>-->
                    </div>
                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Arxiv PDF link -->
                            <!--                            <span class="link-block">-->
                            <!--                        <a class="external-link button is-normal is-rounded is-dark"-->
                            <!--                           href="https://arxiv.org/pdf/2403.04701.pdf"-->
                            <!--                           target="_blank">-->
                            <!--                        <span class="icon">-->
                            <!--                          <i class="fas fa-file-pdf"></i>-->
                            <!--                        </span>-->
                            <!--                        <span>Paper</span>-->
                            <!--                      </a>-->
                            <!--                    </span>-->

                            <!--                            &lt;!&ndash; Supplementary PDF link &ndash;&gt;-->
                            <!--                            <span class="link-block">-->
                            <!--                      <a class="external-link button is-normal is-rounded is-dark" href="static/pdfs/sample.pdf"-->
                            <!--                         target="_blank">-->
                            <!--                      <span class="icon">-->
                            <!--                        <i class="fas fa-file-pdf"></i>-->
                            <!--                      </span>-->
                            <!--                      <span>Supplementary</span>-->
                            <!--                    </a>-->
                            <!--                  </span>-->
                            <!-- ArXiv abstract Link -->
                            <span class="link-block">
                  <a class="external-link button is-normal is-rounded is-dark" href="https://arxiv.org/abs/2503.10629"
                     target="_blank">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                            <!-- Github link -->
                            <span class="link-block">
                    <a class="external-link button is-normal is-rounded is-dark"
                       href="https://github.com/HashmatShadab/HSAT"
                       target="_blank">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                            <!-- Model Zoo (Google Drive) link -->
                            <!--            <span class="link-block">-->
                            <!--                <a class="external-link button is-normal is-rounded is-dark"-->
                            <!--                   href="https://drive.google.com/drive/folders/1mt5zbiWi_ZYNJyDCpJ33Zc3AFZ9NxaLr?usp=sharing"-->
                            <!--                   target="_blank">-->
                            <!--                    <span class="icon">-->
                            <!--                        <i class="fas fa-hdd"></i> &lt;!&ndash; Hard drive icon &ndash;&gt;-->
                            <!--                    </span>-->
                            <!--                    <span>Model Weights</span>-->
                            <!--                </a>-->
                            <!--            </span>-->


                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <img src="./static/images/conceptfigure.png"><br>
            <h2 class="subtitle has-text-centered">
                <p align="justify">
                    Current adversarial training methods in self-supervised learning primarily focus on <em>instance-level
                    contrastive learning</em>, where adversarial perturbations are generated by <em>pushing</em> an
                    image away from
                    its own augmented views. However, such approaches often overlook the rich hierarchical structure
                    present in complex domains like histopathology. In contrast, we introduce <em>Hierarchical
                    Self-Supervised Adversarial Training</em> <b>(HSAT)</b>, a framework that extends adversarial
                    training beyond
                    the instance level by leveraging hierarchical positives — <b>Patch Positives</b> (augmented views of
                    a
                    patch), <b>Slide Positives</b> (patches from the same slide), and <b>Patient Positives</b> (patches
                    from slides of
                    the same patient). By jointly optimizing contrastive objectives at multiple hierarchies, <b>HSAT</b>
                    reduces overfitting to specific adversarial patterns and strengthens the model’s ability to
                    generalize across complex relationships in histopathology data. Our method involves two key steps:


                <div style="background-color: #f0f8ff; padding: 10px; border-radius: 5px; margin-bottom: 10px; text-align: justify;">
                    <b><span style="color: blue;">Maximization Step:</span></b> We generate adversarial examples by
                    pushing an image away from its positive pairs across all hierarchical levels, crafting diverse
                    perturbations that challenge the model not just at the patch level but also across slide and patient
                    relationships.
                </div>

                <div style="background-color: #ffe4e1; padding: 10px; border-radius: 5px; text-align: justify;">
                    <b><span style="color: blue;">Minimization Step:</span></b> The encoder is then updated by pulling
                    these adversarial examples closer to their corresponding hierarchical positives in the feature
                    space, reinforcing robust feature representations across all levels.
                </div>

            </h2>
        </div>
    </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Adversarial attacks pose significant challenges for vision models in critical fields like
                        healthcare, where reliability is essential. Although adversarial training has been well studied
                        in natural images, its application to biomedical and microscopy data remains limited. Existing
                        self-supervised adversarial training methods overlook the hierarchical structure of
                        histopathology images, where patient-slide-patch relationships provide valuable discriminative
                        signals. To address this, we propose <em>Hierarchical Self-Supervised Adversarial Training</em>
                        <b>(HSAT)</b>, which exploits these properties to craft adversarial examples using multi-level
                        contrastive learning and integrate it into adversarial training for enhanced robustness. We
                        evaluate <b>HSAT</b> on multiclass histopathology
                        dataset OpenSRH and the results show that <b>HSAT</b> outperforms existing methods from both
                        biomedical and natural image domains. <b>HSAT</b> enhances robustness, achieving an average
                        gain of 54.31% in the white-box setting and reducing performance drops to 3-4% in the
                        black-box setting, compared to 25-30% for the baseline. These results set a new benchmark for
                        adversarial training in this domain, paving the way for more robust models. Our code and
                        pretrained models will be made publicly available.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->

<!-- Tabular Results -->
<!--  Results will be in the form of images-->
<section class="hero is-small is-light">
    <div class="hero-body">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Quantitative Results</h2>
                <div class="item" style="margin-bottom: 40px;">
                    <!-- Your image here -->
                    <img alt="MY ALT TEXT" src="static/images/table1.png" style="width: 70%;"/>
                    <h2 class="subtitle has-text-centered" style="width: 70%; margin: 0 auto; text-align: justify;">
                        <p>We observe that vision models trained using our <strong>HSAT</strong> framework exhibit
                            significantly higher adversarial robustness in white-box settings compared to baseline
                            methods. Under the PGD attack at <em>&#949; = 8/255</em> using a ResNet-50 backbone,
                            <strong>HSAT</strong> achieves gains of <strong>43.90%</strong>, <strong>60.70%</strong>,
                            and <strong>58.33%</strong> in <em>patch</em>, <em>slide</em>, and <em>patient
                                classification</em>, respectively, compared to non-adversarial hierarchical training
                            methods. Additionally, <strong>HSAT</strong> outperforms instance-level adversarial training
                            (<strong>HSAT-Patch</strong>) by <strong>6.68%</strong>, <strong>10.51%</strong>, and
                            <strong>10%</strong> across the same tasks. Despite a slight drop in clean accuracy compared
                            to non-adversarial methods, <strong>HSAT</strong> maintains a superior clean performance
                            with improvements of <strong>15.68%</strong>, <strong>17.12%</strong>, and
                            <strong>20%</strong> over <strong>HSAT-Patch</strong>.</p>


                    </h2>
                </div>
                <div class="item" style="margin-bottom: 40px;">
                    <!-- Your image here -->
                    <img alt="MY ALT TEXT" src="static/images/table2.png" style="width: 70%;"/>
                    <h2 class="subtitle has-text-centered" style="width: 70%; margin: 0 auto; text-align: justify;">
                        <p>We observe that target vision models trained using our <strong>HSAT</strong> framework are
                            significantly more robust against transferability of adversarial examples crafted across
                            different surrogate models. On average, <strong>HSAT</strong> trained target models show a
                            performance drop of around <strong>3-4%</strong>, while target models trained using <strong>Hidisc</strong>
                            show a performance drop of around <strong>25-30%</strong>.</p>
                    </h2>
                </div>
                <div class="item" style="margin-bottom: 40px;">
                    <!-- Your image here -->
                    <img alt="MY ALT TEXT" src="static/images/table3_4.png" style="width: 70%;"/>
                    <h2 class="subtitle has-text-centered" style="width: 70%; margin: 0 auto; text-align: justify;">
                        <p>Ablation studies for Hierarchical Adversarial Training (<strong>HSAT</strong>) in Tables 3
                            and 4 show that increasing hierarchical discrimination—progressing from patch-level
                            (<strong>HSAT-Patch</strong>) to slide-level (<strong>HSAT-Slide</strong>) and patient-level
                            (<strong>HSAT-Patient</strong>)—consistently improves adversarial robustness. These results highlight the effectiveness of multi-level
                            adversarial training in aligning robust representations across hierarchical levels.</p>
                    </h2>
                </div>


            </div>
        </div>
    </div>


</section>

<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{malik2025hierarchical,
  title={Hierarchical Self-Supervised Adversarial Training for Robust Vision Models in Histopathology},
  author={Malik, Hashmat Shadab and Kunhimon, Shahina and Naseer, Muzammal and Khan, Fahad Shahbaz and Khan, Salman},
  journal={arXiv preprint arXiv:2503.10629},
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">

                    <p>
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                        Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io"
                                                                                target="_blank">Nerfies</a> project
                        page.
                    </p>

                </div>
            </div>
        </div>
    </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->


<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->


</body>
</html>
